{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SnakeNgs documentation","text":"<p>Pipelines for NGS data analysis written in Snakemake. Each pipeline is designed to be executed with Singularity containers.</p>"},{"location":"#quick-start","title":"Quick start","text":"<ol> <li> <p>Make sure you have Singularity and Snakemake installed.</p> </li> <li> <p>Clone the repository and run the pipeline of your choice (e.g., <code>preprocessing_RNAseq.smk</code>).</p> </li> </ol> <pre><code># Clone the repository\ngit clone https://github.com/NaotoKubota/SnakeNgs.git\n\n# Run the pipeline\nsnakemake -s /path/to/SnakeNgs/snakefile/preprocessing_RNAseq.smk \\\n--configfile /path/to/config.yaml \\\n--cores 16 \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre>"},{"location":"#contents","title":"Contents","text":"<ul> <li>Installation</li> <li>Tutorial<ul> <li>Fetching public NGS data</li> <li>QC and mapping for RNA-seq</li> <li>UMI count from single-nucleus RNA-seq</li> <li>QC, mapping, peak calling for ChIP-seq/ATAC-seq</li> </ul> </li> <li>Usage<ul> <li>Fetching<ul> <li>ngsFetch</li> </ul> </li> <li>RNA-seq<ul> <li>preprocessing_RNAseq.smk</li> <li>preprocessing_RNAseq_single.smk</li> <li>rMATS.smk</li> <li>SUPPA2_diffSplice.smk</li> <li>Whippet.smk</li> <li>MAJIQ.smk</li> <li>LeafCutter.smk</li> </ul> </li> <li>snRNA-seq<ul> <li>kb-nac.smk</li> </ul> </li> <li>ChIP-seq<ul> <li>preprocessing_ChIPseq.smk</li> <li>preprocessing_ChIPseq_single.smk</li> <li>callpeak_ChIPseq.smk</li> </ul> </li> <li>ATAC-seq<ul> <li>callpeak_ATACseq.smk</li> <li>differential_ATACseq.smk</li> <li>footprinting_ATACseq.smk</li> </ul> </li> <li>iCLIP-seq &amp; HITSCLIP<ul> <li>preprocessing_iCLIPseq.smk</li> <li>preprocessing_HITSCLIP.smk</li> </ul> </li> <li>File format conversion<ul> <li>bam2cram.smk</li> </ul> </li> </ul> </li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>You don't have to build a local environment for each pipeline! All pipelines are executable in a Docker or Singularity container with Snakemake so that you can run the pipelines on your local machine, HPC, or cloud environment.</p>"},{"location":"installation/#docker","title":"Docker","text":"<p>To install Docker, please follow the instructions here.</p>"},{"location":"installation/#singularity","title":"Singularity","text":"<p>Singualrity is a container platform that is more suitable for HPC environments. To install Singularity, please follow the instructions here. Note that you need to have root access to install Singularity.</p>"},{"location":"installation/#snakemake","title":"Snakemake","text":"<p>For executing any snakefiles ending with <code>.smk</code>, you need to install Snakemake and Singularity. Please follow the instructions here to install Snakemake.</p>"},{"location":"installation/#clone-the-repository","title":"Clone the repository","text":"<p>You can pull the GitHub repository containing all the pipelines by running the following command:</p> <pre><code># Clone the repository\ngit clone https://github.com/NaotoKubota/SnakeNgs\n</code></pre>"},{"location":"tutorial/ChIP-ATAC_preprocessing_callpeak/","title":"QC, mapping, peak calling for ChIP-seq/ATAC-seq","text":""},{"location":"tutorial/Fetching/","title":"Fetching public NGS Data","text":"<p>Let's say you want to fetch the data from the public server (GEO) using the ID GSE52856, which is a dataset of RNA-seq data from N2a mouse cell lines treated with shRNA against the gene Ptbp1 and/or Ptbp2, and store the data in the directory <code>/path/to/output</code>. The command will be:</p> <pre><code># Docker\ndocker run --rm -v $(PWD):$(PWD) naotokubota/snakengs:latest \\\nngsFetch -i GSE52856 -o $(PWD)/GSE52856\n\n# Singularity\nsingularity exec docker://naotokubota/snakengs:latest \\\nngsFetch -i GSE52856 -o ./GSE52856\n</code></pre> <p><code>./GSE52856</code> will contain the data fetched from the public server:</p> <pre><code>GSE52856/\n\u251c\u2500\u2500 fastq\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 log\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 md5sum.log\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1043121_1.fastq.gz.log\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1043121_2.fastq.gz.log\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1043122_1.fastq.gz.log\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1043122_2.fastq.gz.log\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1107524_1.fastq.gz.log\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1107524_2.fastq.gz.log\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1107525_1.fastq.gz.log\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 SRR1107525_2.fastq.gz.log\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1043121_1.fastq.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1043121_2.fastq.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1043122_1.fastq.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1043122_2.fastq.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1107524_1.fastq.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1107524_2.fastq.gz\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 SRR1107525_1.fastq.gz\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 SRR1107525_2.fastq.gz\n\u251c\u2500\u2500 GSE52856_fastq_ftp.txt\n\u2514\u2500\u2500 GSE52856_metadata.json\n</code></pre> <p><code>fastq</code> directory contains the fastq files fetched from the public server, and <code>GSE52856_fastq_ftp.txt</code> and <code>GSE52856_metadata.json</code> are the files containing the FTP links and metadata of the fetched data, respectively. <code>md5sum.log</code> files are the log files for the MD5 check of the fetched data. If the MD5 check succeeds, <code>md5sum.log</code> will contain the message below:</p> <pre><code>./GSE52856/fastq/SRR1043121_1.fastq.gz: OK\n./GSE52856/fastq/SRR1043121_2.fastq.gz: OK\n./GSE52856/fastq/SRR1043122_1.fastq.gz: OK\n./GSE52856/fastq/SRR1043122_2.fastq.gz: OK\n./GSE52856/fastq/SRR1107524_1.fastq.gz: OK\n./GSE52856/fastq/SRR1107524_2.fastq.gz: OK\n./GSE52856/fastq/SRR1107525_1.fastq.gz: OK\n./GSE52856/fastq/SRR1107525_2.fastq.gz: OK\n</code></pre>"},{"location":"tutorial/RNAseq_preprocessing/","title":"QC and mapping for RNA-seq","text":""},{"location":"tutorial/snRNAseq_count/","title":"UMI count from single-nucleus RNA-seq","text":""},{"location":"usage/LeafCutter/","title":"LeafCutter.smk","text":"<p>Snakemake workflow for differential RNA splicing analysis using LeafCutter.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/LeafCutter/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Extract junction reads using regtools <code>junctions extract</code>.</li> <li>Cluster introns using LeafCutter <code>leafcutter_cluster_regtools.py</code>.</li> <li>Extract exon information using LeafCutter <code>gtf_to_exons.R</code>.</li> <li>Differential splicing analysis using LeafCutter <code>leafcutter_ds.R</code>.</li> <li>Plot splice junctions using LeafCutter <code>ds_plots.R</code>.</li> <li>Make annotation codes using LeafCutter <code>gtf2leafcutter.pl</code>.</li> <li>Prepare results for visualization in LeafViz using LeafCutter <code>prepare_results.R</code>.</li> <li>Classify clusters using LeafCutter <code>classify_clusters.R</code>.</li> </ol>"},{"location":"usage/LeafCutter/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/LeafCutter.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code>workdir: /path/to/output\nexperiment_table: /path/to/experiment_table.tsv\ngtf: /path/to/reference_transcriptome.gtf\n\n# Junction read filtering\nminimum_anchor_length: 6 # Minimum anchor length\nminimum_intron_length: 70 # Minimum intron length\nmaximum_intron_length: 500000 # Maximum intron length\nstrand: XS # Strand information in BAM file\n\n# Intron clustering\nminimum_reads: 10\n\n# Differential splicing analysis\nmin_coverage: 10 # Minimum coverage\nmin_samples_per_intron: 1 # Minimum samples per intron\nmin_samples_per_group: 1 # Minimum samples per group\nFDR: 0.05 # False discovery rate\n</code></pre> <ul> <li><code>/path/to/output</code> is the directory where the output files will be saved.</li> <li><code>/path/to/experiment_table.tsv</code> is a tab-separated file, which is same as the one used in Shiba.</li> </ul> <pre><code>sample  bam group\nsample1 /path/to/sample1.bam    Ref\nsample2 /path/to/sample2.bam    Ref\nsample3 /path/to/sample3.bam    Ref\nsample4 /path/to/sample4.bam    Alt\nsample5 /path/to/sample5.bam    Alt\nsample6 /path/to/sample6.bam    Alt\n</code></pre> <p>The <code>group</code> column must be specified as <code>Ref</code> or <code>Alt</code>. This workflow will perform the differential splicing analysis between the two groups.</p> <ul> <li> <p><code>/path/to/reference_transcriptome.gtf</code> is the reference transcriptome in GTF format (e.g. <code>Homo_sapiens.GRCh38.106.gtf</code> for human transcriptome).</p> </li> <li> <p><code>minimum_anchor_length</code> is the minimum anchor length for the junction reads.</p> </li> <li><code>minimum_intron_length</code> is the minimum intron length for the junction reads.</li> <li><code>maximum_intron_length</code> is the maximum intron length for the junction reads.</li> <li><code>strand</code> is the strand information in the BAM file, where <code>XS</code> is used for unstranded data. Please refer to the regtools documentation for more information.</li> <li><code>minimum_reads</code> is the minimum number of reads required to cluster the introns.</li> <li><code>min_coverage</code> is the minimum coverage required for the intron to be considered.</li> <li><code>min_samples_per_intron</code> is the minimum number of samples required for the intron to be considered.</li> <li><code>min_samples_per_group</code> is the minimum number of samples required for the group to be considered.</li> <li><code>FDR</code> is the false discovery rate for the differential splicing analysis.</li> </ul>"},{"location":"usage/LeafCutter/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>griffithlab/regtools:release-1.0.0</li> <li>naotokubota/leafcutter:0.2.9</li> </ul>"},{"location":"usage/MAJIQ/","title":"MAJIQ.smk","text":"<p>Snakemake workflow for differential RNA splicing analysis using MAJIQ.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/MAJIQ/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Parse the experiment table to create a setting file for MAJIQ.</li> <li>Build splicegraph using MAJIQ <code>build</code>.</li> <li>Differential splicing analysis using MAJIQ <code>heterogen</code> and <code>deltapsi</code>.</li> <li>Make a tab-separated summary of the results using MAJIQ <code>voila tsv</code>.</li> <li>Modulize the results using MAJIQ <code>voila modulize</code>.</li> </ol>"},{"location":"usage/MAJIQ/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/MAJIQ.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code>workdir: /path/to/output\ncontainer: /path/to/singularity_image\nexperiment_table: /path/to/experiment_table.tsv\ngff: /path/to/reference_transcriptome.gff3\ngenome: hg19 # hg19, hg38, mm10, mm39, etc.\nstrandness: None # [None, forward, reverse]\n</code></pre> <ul> <li><code>/path/to/output</code> is the directory where the output files will be saved.</li> <li><code>/path/to/singularity_image</code> is the path to the Singularity image file for MAJIQ.</li> </ul> <p>Note</p> <p>As of now, there is no public Docker/Singularity image available for MAJIQ. You need to build the image by yourself. Please refer to the MAJIQ installation guide for more information.</p> <ul> <li><code>/path/to/experiment_table.tsv</code> is a tab-separated file, which is same as the one used in Shiba.</li> </ul> <pre><code>sample  bam group\nsample1 /path/to/sample1.bam    Ref\nsample2 /path/to/sample2.bam    Ref\nsample3 /path/to/sample3.bam    Ref\nsample4 /path/to/sample4.bam    Alt\nsample5 /path/to/sample5.bam    Alt\nsample6 /path/to/sample6.bam    Alt\n</code></pre> <p>The <code>group</code> column must be specified as <code>Ref</code> or <code>Alt</code>. This workflow will perform the differential splicing analysis between the two groups.</p> <ul> <li><code>/path/to/reference_transcriptome.gff3</code> is the reference transcriptome in GFF3 format (e.g. <code>Homo_sapiens.GRCh38.106.gff3</code> for human transcriptome).</li> <li><code>genome</code> is the genome version used in the analysis (e.g. <code>hg19</code>, <code>hg38</code>, <code>mm10</code>, <code>mm39</code>, etc.).</li> <li><code>strandness</code> is the strandness of the RNA-seq data. (<code>None</code>, <code>forward</code>, <code>reverse</code>)</li> </ul>"},{"location":"usage/MAJIQ/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<p>No public Docker image is available for MAJIQ.</p>"},{"location":"usage/SUPPA2_diffSplice/","title":"SUPPA2_diffSplice.smk","text":"<p>Snakemake workflow for differential RNA splicing analysis using SUPPA2.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/SUPPA2_diffSplice/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Quantify transcript abundances (TPM) for each sample using salmon.</li> <li>Merge the quantification results into a single file.</li> <li>Make a list of alternative splicing events using SUPPA2 <code>generateEvents</code>.</li> <li>Quantify Percent Spliced In (PSI) values using SUPPA2 <code>psiPerEvent</code>.</li> <li>Separate the PSI values into two groups.</li> <li>Separate the TPM values into two groups.</li> <li>Differential splicing analysis using SUPPA2 <code>diffSplice</code>.</li> </ol>"},{"location":"usage/SUPPA2_diffSplice/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/SUPPA2_diffSplice.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code>workdir: /path/to/output\nexperiment_table: /path/to/experiment_table.tsv\nsalmon_index: /path/to/salmon_index\ngtf: /path/to/reference_transcriptome.gtf\n</code></pre> <ul> <li><code>/path/to/output</code> is the directory where the output files will be saved.</li> <li><code>/path/to/experiment_table.tsv</code> is a tab-separated file containing the following information:</li> </ul> <pre><code>sample  fastq   group\nsample1 /path/to/sample1_R1.fastq.gz,/path/to/sample1_R2.fastq.gz   Ref\nsample2 /path/to/sample2_R1.fastq.gz,/path/to/sample2_R2.fastq.gz   Ref\nsample3 /path/to/sample3_R1.fastq.gz,/path/to/sample3_R2.fastq.gz   Ref\nsample4 /path/to/sample4_R1.fastq.gz,/path/to/sample4_R2.fastq.gz   Alt\nsample5 /path/to/sample5_R1.fastq.gz,/path/to/sample5_R2.fastq.gz   Alt\nsample6 /path/to/sample6_R1.fastq.gz,/path/to/sample6_R2.fastq.gz   Alt\n</code></pre> <p>The <code>fastq</code> column should contain the paths to the FASTQ files for each sample. R1 and R2 files should be separated by a comma. The <code>group</code> column must be specified as <code>Ref</code> or <code>Alt</code>. This workflow will perform the differential splicing analysis between the two groups.</p> <ul> <li><code>/path/to/salmon_index</code> is the directory containing the salmon index.</li> <li><code>/path/to/reference_transcriptome.gtf</code> is the reference transcriptome in GTF format (e.g. <code>Homo_sapiens.GRCh38.106.gtf</code> for human transcriptome).</li> </ul>"},{"location":"usage/SUPPA2_diffSplice/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>combinelab/salmon:1.10.1</li> <li>naotokubota/suppa:2.3</li> </ul>"},{"location":"usage/Whippet/","title":"Whippet.smk","text":"<p>Snakemake workflow for differential RNA splicing analysis using Whippet.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/Whippet/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Quantify Percent Spliced In (PSI) values using Whippet <code>quant</code>.</li> <li>Differential splicing analysis using Whippet <code>delta</code>.</li> </ol>"},{"location":"usage/Whippet/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/Whippet.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code>workdir: /path/to/output\nexperiment_table: /path/to/experiment_table.tsv\nwhippet_index: /path/to/whippet_index/graph.jls\n</code></pre> <ul> <li><code>/path/to/output</code> is the directory where the output files will be saved.</li> <li><code>/path/to/experiment_table.tsv</code> is a tab-separated file containing the following information:</li> </ul> <pre><code>sample  fastq   group\nsample1 /path/to/sample1_R1.fastq.gz,/path/to/sample1_R2.fastq.gz   Ref\nsample2 /path/to/sample2_R1.fastq.gz,/path/to/sample2_R2.fastq.gz   Ref\nsample3 /path/to/sample3_R1.fastq.gz,/path/to/sample3_R2.fastq.gz   Ref\nsample4 /path/to/sample4_R1.fastq.gz,/path/to/sample4_R2.fastq.gz   Alt\nsample5 /path/to/sample5_R1.fastq.gz,/path/to/sample5_R2.fastq.gz   Alt\nsample6 /path/to/sample6_R1.fastq.gz,/path/to/sample6_R2.fastq.gz   Alt\n</code></pre> <p>The <code>fastq</code> column should contain the paths to the FASTQ files for each sample. R1 and R2 files should be separated by a comma. The <code>group</code> column must be specified as <code>Ref</code> or <code>Alt</code>. This workflow will perform the differential splicing analysis between the two groups.</p> <ul> <li><code>/path/to/whippet_index/graph.jls</code> is the Whippet index file.</li> </ul>"},{"location":"usage/Whippet/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>cloxd/whippet:1.6.1</li> </ul>"},{"location":"usage/bam2cram/","title":"bam2cram.smk","text":"<p>Snakemake workflow for file format conversion from BAM to CRAM to compress the file size.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/bam2cram/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Convert BAM files to CRAM files using samtools.</li> <li>Make CRAM index files (<code>.crai</code>) using samtools.</li> </ol>"},{"location":"usage/bam2cram/#usage","title":"Usage","text":"<pre><code>snakemake -s /rhome/naotok/SnakeNgs/Snakefile_bam2cram \\\n--config \\\nworkdir=/path/to/output \\\nreference=/path/to/reference_genome.fa \\\nbam_list=/path/to/bam_list.txt \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <ul> <li><code>path/to/output</code> is the directory where the log files will be saved.</li> <li><code>path/to/reference_genome.fa</code> is the reference genome file in FASTA format (e.g., <code>Mus_musculus.GRCm38.dna_sm.primary_assembly.fa</code> for mouse genome).</li> <li><code>path/to/bam_list.txt</code> is a text file containing the list of BAM files to be converted to CRAM files:</li> </ul> <pre><code>/path/to/SRRXXXXXX.bam\n/path/to/SRRYYYYYY.bam\n/path/to/SRRZZZZZZ.bam\n/path/to/SRRAAAAAA.bam\n/path/to/SRRBBBBBB.bam\n/path/to/SRRCCCCCC.bam\n</code></pre> <p>The CRAM files will be saved in the same directory as the input BAM files with the <code>.cram</code> extension.</p>"},{"location":"usage/bam2cram/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>quay.io/biocontainers/samtools:1.18--h50ea8bc_1</li> </ul>"},{"location":"usage/callpeak_ATACseq/","title":"callpeak_ATACseq.smk","text":"<p>Snakemake workflow for peak calling of ATAC-seq data.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/callpeak_ATACseq/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Peak calling using MACS with the parameter specified in the <code>config.yaml</code>.</li> <li>Convert bedgraph files to bigwig files using bedgraphtobigwig.</li> <li>Make summary statistics using MultiQC.</li> </ol>"},{"location":"usage/callpeak_ATACseq/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/callpeak_ATACseq.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code># general\nworkdir: /path/to/output\nsamples: [\"SRRXXXXXX\", \"SRRYYYYYY\", \"SRRZZZZZZ\"]\n\n# macs2\nbroad: False # Boolean\nbroad_cutoff: # Float when broad is True\ngenomesize: hs # [\"hs\", \"mm\", \"ce\", \"dm\"]\nfileformat: BAMPE # [\"BED\", \"BAM\", \"SAM\", \"BEDPE\", \"BAMPE\"]\nqvalue: 0.05\n\n# bedgraphtobigwig\nassembly: hg38\n</code></pre> <ul> <li><code>path/to/output</code> should contain <code>fastq</code> directory with the following structure:</li> </ul> <pre><code>output/\n\u2514\u2500\u2500 bowtie2\n    \u251c\u2500\u2500 SRRXXXXXX.sort.rmdup.bam\n    \u251c\u2500\u2500 SRRYYYYYY.sort.rmdup.bam\n    \u2514\u2500\u2500 SRRZZZZZZ.sort.rmdup.bam\n</code></pre> <p>Is is expected that the input BAM files are generated by the preprocessing_ChIPseq.smk workflow.</p> <ul> <li> <p><code>macs2</code> contains the parameters for MACS2 peak calling. Please refer to the MACS2 documentation.</p> </li> <li> <p><code>bedgraphtobigwig</code> contains the assembly information for the conversion of bedgraph files to bigwig files.</p> </li> </ul>"},{"location":"usage/callpeak_ATACseq/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>quay.io/biocontainers/macs2:2.2.9.1--py39hf95cd2a_0</li> <li>quay.io/biocontainers/ucsc-bedgraphtobigwig:445--h954228d_0</li> <li>multiqc/multiqc:v1.25</li> </ul>"},{"location":"usage/callpeak_ChIPseq/","title":"callpeak_ChIPseq.smk","text":"<p>Snakemake workflow for peak calling of ChIP-seq data.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/callpeak_ChIPseq/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Peak calling using MACS with the parameter specified in the <code>config.yaml</code>.</li> <li>Convert bedgraph files to bigwig files using bedgraphtobigwig.</li> <li>Make summary statistics using MultiQC.</li> </ol>"},{"location":"usage/callpeak_ChIPseq/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/callpeak_ChIPseq.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code>general:\n  workdir: /path/to/output\n  experiment_table: /path/to/experiment_table.tsv\n\nmacs2:\n  broad: False # Boolean\n  broad_cutoff: # Float when broad is True\n  genomesize: hs # [\"hs\", \"mm\", \"ce\", \"dm\"]\n  fileformat: BAM # [\"BED\", \"BAM\", \"SAM\", \"BEDPE\", \"BAMPE\"]\n  qvalue: 0.05\n\nbedgraphtobigwig:\n  assembly: hg38\n</code></pre> <ul> <li><code>experiment_table.tsv</code> should contain the following information:</li> </ul> <pre><code>sample  target  control\nsample1 /path/to/sample1_target.bam /path/to/control_A.bam\nsample2 /path/to/sample2_target.bam /path/to/control_B.bam\nsample3 /path/to/sample3_target.bam /path/to/control_A.bam\n</code></pre> <p><code>target</code> and <code>control</code> are paths to the BAM files for the target and control (input) samples, respectively.</p> <ul> <li> <p><code>macs2</code> contains the parameters for MACS2 peak calling. Please refer to the MACS2 documentation.</p> </li> <li> <p><code>bedgraphtobigwig</code> contains the assembly information for the conversion of bedgraph files to bigwig files.</p> </li> </ul>"},{"location":"usage/callpeak_ChIPseq/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>quay.io/biocontainers/macs2:2.2.9.1--py39hf95cd2a_0</li> <li>quay.io/biocontainers/ucsc-bedgraphtobigwig:445--h954228d_0</li> <li>multiqc/multiqc:v1.25</li> </ul>"},{"location":"usage/differential_ATACseq/","title":"differential_ATACseq.smk","text":"<p>Snakemake workflow for differential analysis of ATAC-seq data.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/differential_ATACseq/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Merge peak resions from all samples using bedtools <code>merge</code>.</li> <li>Read count for each peak region using featureCounts.</li> <li>Differential analysis using DESeq2.</li> </ol>"},{"location":"usage/differential_ATACseq/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/differential_ATACseq.smk \\\n--config \\\nworkdir=/path/to/output \\\nexperiment_table=/path/to/experiment_table.tsv \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <ul> <li><code>path/to/output</code> is the directory where the output files will be saved.</li> <li><code>path/to/experiment_table.tsv</code> is a tab-separated file containing the following information:</li> </ul> <pre><code>sample  bam peak    group\nSRRXXXXXX   /path/to/SRRXXXXXX.sort.rmdup.bam   /path/to/SRRXXXXXX_peaks.narrowPeak Ref\nSRRYYYYYY   /path/to/SRRYYYYYY.sort.rmdup.bam   /path/to/SRRYYYYYY_peaks.narrowPeak Ref\nSRRZZZZZZ   /path/to/SRRZZZZZZ.sort.rmdup.bam   /path/to/SRRZZZZZZ_peaks.narrowPeak Ref\nSRRAAAAAA   /path/to/SRRAAAAAA.sort.rmdup.bam   /path/to/SRRAAAAAA_peaks.narrowPeak Alt\nSRRBBBBBB   /path/to/SRRBBBBBB.sort.rmdup.bam   /path/to/SRRBBBBBB_peaks.narrowPeak Alt\nSRRCCCCCC   /path/to/SRRCCCCCC.sort.rmdup.bam   /path/to/SRRCCCCCC_peaks.narrowPeak Alt\n</code></pre> <p>It is expected that the input BAM files are generated by the preprocessing_ChIPseq.smk workflow and the peak files are generated by the callpeak_ATACseq.smk workflow.</p>"},{"location":"usage/differential_ATACseq/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>quay.io/biocontainers/bedtools:2.24--1</li> <li>quay.io/biocontainers/subread:2.0.6--he4a0461_0</li> <li>quay.io/biocontainers/bioconductor-deseq2:1.42.0--r43hf17093f_0</li> </ul>"},{"location":"usage/footprinting_ATACseq/","title":"footprinting_ATACseq.smk","text":"<p>Snakemake workflow for footprinting analysis of ATAC-seq data using TOBIAS.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/footprinting_ATACseq/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Merge peak resions from all samples using bedtools <code>merge</code>.</li> <li>Merge bam files from all samples using samtools <code>merge</code>.</li> <li>Bias correction of ATAC-seq reads in open chromatin using TOBIAS <code>ATACorrect</code>.</li> <li>Calculate footprint scores from corrected cutsites using TOBIAS <code>FootprintScores</code>.</li> <li>Estimation of differentially bound motifs based on scores, sequence and motifs using TOBIAS <code>BINDetect</code>.</li> </ol>"},{"location":"usage/footprinting_ATACseq/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/footprinting_ATACseq.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code># general\nworkdir: /path/to/output\nexperiment_table: /path/to/experiment_table.tsv\n\n# TOBIAS\ngenome_fasta: /path/to/genome.fa\ncluster_motifs: /path/to/motifs\n</code></pre> <ul> <li><code>path/to/output</code> is the directory where the output files will be saved.</li> <li><code>path/to/experiment_table.tsv</code> is a tab-separated file containing the following information:</li> </ul> <pre><code>sample  bam peak    group\nSRRXXXXXX   /path/to/SRRXXXXXX.sort.rmdup.bam   /path/to/SRRXXXXXX_peaks.narrowPeak Ref\nSRRYYYYYY   /path/to/SRRYYYYYY.sort.rmdup.bam   /path/to/SRRYYYYYY_peaks.narrowPeak Ref\nSRRZZZZZZ   /path/to/SRRZZZZZZ.sort.rmdup.bam   /path/to/SRRZZZZZZ_peaks.narrowPeak Ref\nSRRAAAAAA   /path/to/SRRAAAAAA.sort.rmdup.bam   /path/to/SRRAAAAAA_peaks.narrowPeak Alt\nSRRBBBBBB   /path/to/SRRBBBBBB.sort.rmdup.bam   /path/to/SRRBBBBBB_peaks.narrowPeak Alt\nSRRCCCCCC   /path/to/SRRCCCCCC.sort.rmdup.bam   /path/to/SRRCCCCCC_peaks.narrowPeak Alt\n</code></pre> <p>It is expected that the input BAM files are generated by the preprocessing_ChIPseq.smk workflow and the peak files are generated by the callpeak_ATACseq.smk workflow.</p> <ul> <li><code>genome.fa</code> is the genome fasta file (e.g. <code>hg38.fa</code>).</li> <li><code>motifs</code> is File containing motifs in either PFM, JASPAR or MEME format. These are the motifs which will be used to scan for binding sites.</li> </ul>"},{"location":"usage/footprinting_ATACseq/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>quay.io/biocontainers/bedtools:2.24--1</li> <li>quay.io/biocontainers/samtools:1.18--h50ea8bc_1</li> <li>quay.io/biocontainers/tobias:0.16.0--py38h24c8ff8_0</li> </ul>"},{"location":"usage/kb-nac/","title":"kb-nac.smk","text":"<p>Snakemake workflow for UMI counting from single-nucleus RNA-seq data with kb-python, a Python wrapper for kallisto and bustools.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/kb-nac/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Build a kallisto index using the reference genome and transcriptome by <code>kb ref</code> with the parameter <code>--workflow nac</code>.</li> <li>Quantify UMI counts using <code>kb count</code> with the parameter <code>--workflow nac --h5ad --gene-names --sum total --filter bustools --overwrite</code>.</li> </ol>"},{"location":"usage/kb-nac/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/kb-nac.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code>workdir: /path/to/output\nexperiment_table: /path/to/experiment_table.tsv\ntechnology: 10xv3 # [10xv1, 10xv2, 10xv3, 10XV3_ULTIMA, BDWTA, INDROPSV3, Visium]\ndna_fasta: /path/to/reference_dna.fa\ngtf: /path/to/reference_transcriptome.gtf\n</code></pre> <ul> <li><code>experiment_table.tsv</code> should contain the following information:</li> </ul> <pre><code>sample  R1  R2\nsample1 path/to/sample1_L001_R1.fastq.gz,path/to/sample1_L002_R1.fastq.gz path/to/sample1_L001_R2.fastq.gz,path/to/sample1_L002_R2.fastq.gz\nsample2 path/to/sample2_L001_R1.fastq.gz,path/to/sample2_L002_R1.fastq.gz path/to/sample2_L001_R2.fastq.gz,path/to/sample2_L002_R2.fastq.gz\nsample3 path/to/sample3_L001_R1.fastq.gz,path/to/sample3_L002_R1.fastq.gz path/to/sample3_L001_R2.fastq.gz,path/to/sample3_L002_R2.fastq.gz\n</code></pre> <p><code>R1</code> and <code>R2</code> are comma-separated paths to the FASTQ files for read 1 and read 2, respectively.</p> <ul> <li><code>technology</code> refer to the assay that generated the data. Supported assays are found in <code>kb --list</code>:</li> </ul> <pre><code>$ singularity exec docker://quay.io/biocontainers/kb-python:0.28.2--pyhdfd78af_2 kb --list\nList of supported single-cell technologies\n\nPositions syntax: `input file index, start position, end position`\nWhen start &amp; end positions are None, refers to the entire file\nCustom technologies may be defined by providing a kallisto-supported technology string\n(see https://pachterlab.github.io/kallisto/manual)\n\nname            description                            on-list    barcode                    umi        cDNA\n------------    -----------------------------------    -------    -----------------------    -------    -----------------------\n10XV1           10x version 1                          yes        0,0,14                     1,0,10     2,None,None\n10XV2           10x version 2                          yes        0,0,16                     0,16,26    1,None,None\n10XV3           10x version 3                          yes        0,0,16                     0,16,28    1,None,None\n10XV3_ULTIMA    10x version 3 sequenced with Ultima    yes        0,22,38                    0,38,50    0,62,None\nBDWTA           BD Rhapsody                            yes        0,0,9 0,21,30 0,43,52      0,52,60    1,None,None\nBULK            Bulk (single or paired)                                                                 0,None,None 1,None,None\nCELSEQ          CEL-Seq                                           0,0,8                      0,8,12     1,None,None\nCELSEQ2         CEL-SEQ version 2                                 0,6,12                     0,0,6      1,None,None\nDROPSEQ         DropSeq                                           0,0,12                     0,12,20    1,None,None\nINDROPSV1       inDrops version 1                                 0,0,11 0,30,38             0,42,48    1,None,None\nINDROPSV2       inDrops version 2                                 1,0,11 1,30,38             1,42,48    0,None,None\nINDROPSV3       inDrops version 3                      yes        0,0,8 1,0,8                1,8,14     2,None,None\nSCRUBSEQ        SCRB-Seq                                          0,0,6                      0,6,16     1,None,None\nSMARTSEQ2       Smart-seq2  (single or paired)                                                          0,None,None 1,None,None\nSMARTSEQ3       Smart-seq3                                                                   0,11,19    0,11,None 1,None,None\nSPLIT-SEQ       SPLiT-seq                                         1,10,18 1,48,56 1,78,86    1,0,10     0,None,None\nSTORMSEQ        STORM-seq                                                                    1,0,8      0,None,None 1,14,None\nSURECELL        SureCell for ddSEQ                                0,0,6 0,21,27 0,42,48      0,51,59    1,None,None\nVisium          10x Visium                             yes        0,0,16                     0,16,28    1,None,None\n</code></pre> <ul> <li> <p><code>reference_dna.fa</code> is the reference genome in FASTA format (e.g., <code>Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa</code>).</p> </li> <li> <p><code>reference_transcriptome.gtf</code> is the reference transcriptome in GTF format (e.g., <code>Homo_sapiens.GRCh38.106.gtf</code>).</p> </li> </ul> <p>Please refer to the tutorial for more information.</p>"},{"location":"usage/kb-nac/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>quay.io/biocontainers/kb-python:0.28.2--pyhdfd78af_2</li> </ul>"},{"location":"usage/ngsFetch/","title":"ngsFetch","text":"<p>Fetching NGS data from the public server using ffq and aria2.</p>"},{"location":"usage/ngsFetch/#usage","title":"Usage","text":"<pre><code>$ docker run --rm naotokubota/snakengs:latest ngsFetch -h\n\n                       ____        __           __         \n                      /\\  _`\\     /\\ \\__       /\\ \\        \n  ___      __     ____\\ \\ \\L\\_\\ __\\ \\ ,_\\   ___\\ \\ \\___    \n/' _ `\\  /'_ `\\  /',__\\\\ \\  _\\/'__`\\ \\ \\/  /'___\\ \\  _ `\\  \n/\\ \\/\\ \\/\\ \\L\\ \\/\\__, `\\\\ \\ \\/\\  __/\\ \\ \\_/\\ \\__/\\ \\ \\ \\ \\ \n\\ \\_\\ \\_\\ \\____ \\/\\____/ \\ \\_\\ \\____\\\\ \\__\\ \\____\\\\ \\_\\ \\_\\\n \\/_/\\/_/\\/___L\\ \\/___/   \\/_/\\/____/ \\/__/\\/____/ \\/_/\\/_/\n           /\\____/                                         \n           \\_/__/                                          \n\nVersion: v0.1\n\n\nngsFetch v0.1 -Pipeline for fetching NGS data-\n\nUsage: ngsFetch -i ID -o output_dir\n\n    -h  Display help\n    -v  Show version\n    -i  ID\n    -o  Output directory\n</code></pre> <p>You are supposed to get the data from the public server using the ID provided by the user. The data will be stored in the output directory after checking the MD5 to ensure the integrity of the data.</p> <p>Please refer to the tutorial for more information.</p>"},{"location":"usage/ngsFetch/#software","title":"Software","text":"<ul> <li>ffq (v0.3.1)</li> <li>aria2</li> </ul>"},{"location":"usage/ngsFetch/#docker-image","title":"Docker image","text":"<ul> <li>naotokubota/snakengs</li> </ul>"},{"location":"usage/preprocessing_ChIPseq/","title":"preprocessing_ChIPseq.smk","text":"<p>Snakemake workflow for preprocessing paired-end ChIP-seq/ATAC-seq data.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/preprocessing_ChIPseq/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Quality control using fastp with the default parameters.</li> <li>Alignment using Bowtie2 with the parameter specified in the <code>config.yaml</code>.</li> <li>Convert the SAM file to BAM file and sort using samtools.</li> <li>Remove duplicates using Picard <code>MarkDuplicates</code> with the parameter <code>--REMOVE_DUPLICATES true</code>.</li> <li>Make fingerprint plots using deepTools <code>plotFingerprint</code> with the parameter <code>--minMappingQuality 30 --skipZeros --numberOfSamples 50000 --binSize 10000</code>.</li> <li>Make bigWig files using deepTools <code>bamCoverage</code> with the parameter <code>--binSize 1 --normalizeUsing CPM</code>.</li> <li>Make summary statistics using MultiQC.</li> </ol>"},{"location":"usage/preprocessing_ChIPseq/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/preprocessing_ChIPseq.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code>workdir: path/to/output\nsamples: [\"SRRXXXXXX\", \"SRRYYYYYY\", \"SRRZZZZZZ\"]\nbowtie2_index: path/to/bowtie2_index\nbowtie2_args: \"\"\n</code></pre> <ul> <li><code>path/to/output</code> should contain <code>fastq</code> directory with the following structure:</li> </ul> <pre><code>output/\n\u2514\u2500\u2500 fastq\n \u00a0\u00a0 \u251c\u2500\u2500 SRRXXXXXX_1.fastq.gz\n \u00a0\u00a0 \u251c\u2500\u2500 SRRXXXXXX_2.fastq.gz\n \u00a0\u00a0 \u251c\u2500\u2500 SRRYYYYYY_1.fastq.gz\n \u00a0\u00a0 \u251c\u2500\u2500 SRRYYYYYY_2.fastq.gz\n \u00a0\u00a0 \u251c\u2500\u2500 SRRZZZZZZ_1.fastq.gz\n \u00a0\u00a0 \u2514\u2500\u2500 SRRZZZZZZ_2.fastq.gz\n</code></pre> <ul> <li> <p><code>path/to/bowtie2_index</code> is the directory containing the Bowtie2 index.</p> </li> <li> <p><code>bowtie2_args</code> is the optional argument for Bowtie2 (e.g., <code>--very-sensitive</code>).</p> </li> </ul> <p>Please refer to the tutorial for more information.</p>"},{"location":"usage/preprocessing_ChIPseq/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>quay.io/biocontainers/fastp:0.23.4--hadf994f_2</li> <li>quay.io/biocontainers/bowtie2:2.5.2--py39h6fed5c7_0</li> <li>quay.io/biocontainers/samtools:1.18--h50ea8bc_1</li> <li>quay.io/biocontainers/picard:3.1.1--hdfd78af_0</li> <li>quay.io/biocontainers/deeptools:3.5.4--pyhdfd78af_1</li> <li>multiqc/multiqc:v1.25</li> </ul>"},{"location":"usage/preprocessing_ChIPseq_single/","title":"preprocessing_ChIPseq_single.smk","text":"<p>Snakemake workflow for preprocessing single-end ChIP-seq/ATAC-seq data.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/preprocessing_ChIPseq_single/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Quality control using fastp with the default parameters.</li> <li>Alignment using Bowtie2 with the parameter specified in the <code>config.yaml</code>.</li> <li>Convert the SAM file to BAM file and sort using samtools.</li> <li>Remove duplicates using Picard <code>MarkDuplicates</code> with the parameter <code>--REMOVE_DUPLICATES true</code>.</li> <li>Make fingerprint plots using deepTools <code>plotFingerprint</code> with the parameter <code>--minMappingQuality 30 --skipZeros --numberOfSamples 50000 --binSize 10000</code>.</li> <li>Make bigWig files using deepTools <code>bamCoverage</code> with the parameter <code>--binSize 1 --normalizeUsing CPM</code>.</li> <li>Make summary statistics using MultiQC.</li> </ol>"},{"location":"usage/preprocessing_ChIPseq_single/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/preprocessing_ChIPseq_single.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code>workdir: path/to/output\nsamples: [\"SRRXXXXXX\", \"SRRYYYYYY\", \"SRRZZZZZZ\"]\nbowtie2_index: path/to/bowtie2_index\nbowtie2_args: \"\"\n</code></pre> <ul> <li><code>path/to/output</code> should contain <code>fastq</code> directory with the following structure:</li> </ul> <pre><code>output/\n\u2514\u2500\u2500 fastq\n \u00a0\u00a0 \u251c\u2500\u2500 SRRXXXXXX.fastq.gz\n \u00a0\u00a0 \u251c\u2500\u2500 SRRYYYYYY.fastq.gz\n \u00a0\u00a0 \u2514\u2500\u2500 SRRZZZZZZ.fastq.gz\n</code></pre> <ul> <li> <p><code>path/to/bowtie2_index</code> is the directory containing the Bowtie2 index.</p> </li> <li> <p><code>bowtie2_args</code> is the optional argument for Bowtie2 (e.g., <code>--very-sensitive</code>).</p> </li> </ul> <p>Please refer to the tutorial for more information.</p>"},{"location":"usage/preprocessing_ChIPseq_single/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>quay.io/biocontainers/fastp:0.23.4--hadf994f_2</li> <li>quay.io/biocontainers/bowtie2:2.5.2--py39h6fed5c7_0</li> <li>quay.io/biocontainers/samtools:1.18--h50ea8bc_1</li> <li>quay.io/biocontainers/picard:3.1.1--hdfd78af_0</li> <li>quay.io/biocontainers/deeptools:3.5.4--pyhdfd78af_1</li> <li>multiqc/multiqc:v1.25</li> </ul>"},{"location":"usage/preprocessing_HITSCLIP/","title":"preprocessing_HITSCLIP.smk","text":"<p>Snakemake workflow for preprocessing HITSCLIP data.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/preprocessing_HITSCLIP/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Quality control using fastp with the parameter <code>-l 20 -3 --trim_front1 5</code>.</li> <li>Alignment using STAR with the parameter <code>--outFilterMultimapNmax 100</code>.</li> <li>Convert the SAM file to BAM file and sort using samtools.</li> <li>Remove duplicates using Picard <code>MarkDuplicates</code> with the parameter <code>--REMOVE_DUPLICATES true</code>.</li> <li>Make bigWig files using deepTools <code>bamCoverage</code> with the parameter <code>--binSize 1</code>.</li> <li>Make summary statistics using MultiQC.</li> </ol>"},{"location":"usage/preprocessing_HITSCLIP/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/preprocessing_HITSCLIP.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code>workdir: /path/to/output\nsamples: [\"SRRXXXXXX\", \"SRRYYYYYY\", \"SRRZZZZZZ\"]\nstar_index: /path/to/star_index\n</code></pre> <ul> <li><code>path/to/output</code> should contain <code>fastq</code> directory with the following structure:</li> </ul> <pre><code>output/\n\u2514\u2500\u2500 fastq\n \u00a0\u00a0 \u251c\u2500\u2500 SRRXXXXXX.fastq.gz\n \u00a0\u00a0 \u251c\u2500\u2500 SRRYYYYYY.fastq.gz\n \u00a0\u00a0 \u2514\u2500\u2500 SRRZZZZZZ.fastq.gz\n</code></pre> <ul> <li><code>path/to/star_index</code> is the directory containing the STAR index.</li> </ul>"},{"location":"usage/preprocessing_HITSCLIP/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>quay.io/biocontainers/fastp:0.23.4--hadf994f_2</li> <li>quay.io/biocontainers/star:2.7.11a--h0033a41_0</li> <li>quay.io/biocontainers/samtools:1.18--h50ea8bc_1</li> <li>quay.io/biocontainers/picard:3.1.1--hdfd78af_0</li> <li>quay.io/biocontainers/deeptools:3.5.4--pyhdfd78af_1</li> <li>multiqc/multiqc:v1.25</li> </ul>"},{"location":"usage/preprocessing_RNAseq/","title":"preprocessing_RNAseq.smk","text":"<p>Snakemake workflow for preprocessing paired-end bulk RNA-seq data.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/preprocessing_RNAseq/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Quality control using fastp with the default parameters.</li> <li>Alignment using STAR with the parameter <code>--outFilterMultimapNmax 1</code>.</li> <li>Convert the SAM file to BAM file and sort using samtools.</li> <li>Collect metrics using Picard <code>CollectRnaSeqMetrics</code> and <code>CollectInsertSizeMetrics</code>.</li> <li>Make bigWig files using deepTools <code>bamCoverage</code> with the parameter <code>--binSize 1</code>.</li> <li>Make summary statistics using MultiQC.</li> </ol>"},{"location":"usage/preprocessing_RNAseq/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/preprocessing_RNAseq.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code>workdir: path/to/output\nsamples: [\"SRRXXXXXX\", \"SRRYYYYYY\", \"SRRZZZZZZ\"]\nstar_index: path/to/star_index\ngtf: path/to/reference_transcriptome.gtf\n</code></pre> <ul> <li><code>path/to/output</code> should contain <code>fastq</code> directory with the following structure:</li> </ul> <pre><code>output/\n\u2514\u2500\u2500 fastq\n \u00a0\u00a0 \u251c\u2500\u2500 SRRXXXXXX_1.fastq.gz\n \u00a0\u00a0 \u251c\u2500\u2500 SRRXXXXXX_2.fastq.gz\n \u00a0\u00a0 \u251c\u2500\u2500 SRRYYYYYY_1.fastq.gz\n \u00a0\u00a0 \u251c\u2500\u2500 SRRYYYYYY_2.fastq.gz\n \u00a0\u00a0 \u251c\u2500\u2500 SRRZZZZZZ_1.fastq.gz\n \u00a0\u00a0 \u2514\u2500\u2500 SRRZZZZZZ_2.fastq.gz\n</code></pre> <ul> <li> <p><code>path/to/star_index</code> is the directory containing the STAR index.</p> </li> <li> <p><code>/path/to/reference_transcriptome.gtf</code> is the reference transcriptome in GTF format (e.g. <code>Homo_sapiens.GRCh38.106.gtf</code> for human transcriptome).</p> </li> </ul> <p>Please refer to the tutorial for more information.</p>"},{"location":"usage/preprocessing_RNAseq/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>quay.io/biocontainers/fastp:0.23.4--hadf994f_2</li> <li>quay.io/biocontainers/star:2.7.11a--h0033a41_0</li> <li>quay.io/biocontainers/samtools:1.18--h50ea8bc_1</li> <li>quay.io/biocontainers/deeptools:3.5.4--pyhdfd78af_1</li> <li>quay.io/biocontainers/picard:3.1.1--hdfd78af_0</li> <li>multiqc/multiqc:v1.25</li> </ul>"},{"location":"usage/preprocessing_RNAseq_single/","title":"preprocessing_RNAseq_single.smk","text":"<p>Snakemake workflow for preprocessing single-end bulk RNA-seq data.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/preprocessing_RNAseq_single/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Quality control using fastp with the default parameters.</li> <li>Alignment using STAR with the parameter <code>--outFilterMultimapNmax 1</code>.</li> <li>Convert the SAM file to BAM file and sort using samtools.</li> <li>Collect metrics using Picard <code>CollectRnaSeqMetrics</code>.</li> <li>Make bigWig files using deepTools <code>bamCoverage</code>.</li> <li>Make summary statistics using MultiQC.</li> </ol>"},{"location":"usage/preprocessing_RNAseq_single/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/preprocessing_RNAseq_single.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code>workdir: path/to/output\nsamples: [\"SRRXXXXXX\", \"SRRYYYYYY\", \"SRRZZZZZZ\"]\nstar_index: path/to/star_index\ngtf: path/to/reference_transcriptome.gtf\n</code></pre> <ul> <li><code>path/to/output</code> should contain <code>fastq</code> directory with the following structure:</li> </ul> <pre><code>output/\n\u2514\u2500\u2500 fastq\n \u00a0\u00a0 \u251c\u2500\u2500 SRRXXXXXX.fastq.gz\n \u00a0\u00a0 \u251c\u2500\u2500 SRRYYYYYY.fastq.gz\n \u00a0\u00a0 \u2514\u2500\u2500 SRRZZZZZZ.fastq.gz\n</code></pre> <ul> <li> <p><code>path/to/star_index</code> is the directory containing the STAR index.</p> </li> <li> <p><code>/path/to/reference_transcriptome.gtf</code> is the reference transcriptome in GTF format (e.g. <code>Homo_sapiens.GRCh38.106.gtf</code> for human transcriptome).</p> </li> </ul> <p>Please refer to the tutorial for more information.</p>"},{"location":"usage/preprocessing_RNAseq_single/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>quay.io/biocontainers/fastp:0.23.4--hadf994f_2</li> <li>quay.io/biocontainers/star:2.7.11a--h0033a41_0</li> <li>quay.io/biocontainers/samtools:1.18--h50ea8bc_1</li> <li>quay.io/biocontainers/deeptools:3.5.4--pyhdfd78af_1</li> <li>quay.io/biocontainers/picard:3.1.1--hdfd78af_0</li> <li>multiqc/multiqc:v1.25</li> </ul>"},{"location":"usage/preprocessing_iCLIPseq/","title":"preprocessing_iCLIPseq.smk","text":"<p>Snakemake workflow for preprocessing iCLIP-seq data.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/preprocessing_iCLIPseq/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Quality control using fastp with the parameters specified in the <code>config.yaml</code>.</li> <li>Alignment using STAR with the parameter <code>--outFilterMultimapNmax 1</code>.</li> <li>Convert the SAM file to BAM file and sort using samtools.</li> <li>Remove duplicates using Picard <code>MarkDuplicates</code> with the parameter <code>--REMOVE_DUPLICATES true</code>.</li> <li>Make bigWig files using deepTools <code>bamCoverage</code> with the parameter <code>--binSize 1 --normalizeUsing CPM</code>.</li> <li>Make summary statistics using MultiQC.</li> </ol>"},{"location":"usage/preprocessing_iCLIPseq/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/preprocessing_iCLIPseq.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code>workdir: /path/to/output\nsamples: [\"SRRXXXXXX\", \"SRRYYYYYY\", \"SRRZZZZZZ\"]\nstar_index: /path/to/star_index\ntrim_front1: 9\nmax_len1: 35\nlength_required: 25\n</code></pre> <ul> <li><code>path/to/output</code> should contain <code>fastq</code> directory with the following structure:</li> </ul> <pre><code>output/\n\u2514\u2500\u2500 fastq\n \u00a0\u00a0 \u251c\u2500\u2500 SRRXXXXXX.fastq.gz\n \u00a0\u00a0 \u251c\u2500\u2500 SRRYYYYYY.fastq.gz\n \u00a0\u00a0 \u2514\u2500\u2500 SRRZZZZZZ.fastq.gz\n</code></pre> <ul> <li> <p><code>path/to/star_index</code> is the directory containing the STAR index.</p> </li> <li> <p><code>trim_front1</code>, <code>max_len1</code>, and <code>length_required</code> are the parameters for fastp.</p> </li> </ul>"},{"location":"usage/preprocessing_iCLIPseq/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>quay.io/biocontainers/fastp:0.23.4--hadf994f_2</li> <li>quay.io/biocontainers/star:2.7.11a--h0033a41_0</li> <li>quay.io/biocontainers/samtools:1.18--h50ea8bc_1</li> <li>quay.io/biocontainers/picard:3.1.1--hdfd78af_0</li> <li>quay.io/biocontainers/deeptools:3.5.4--pyhdfd78af_1</li> <li>multiqc/multiqc:v1.25</li> </ul>"},{"location":"usage/rMATS/","title":"rMATS.smk","text":"<p>Snakemake workflow for differential RNA splicing analysis using rMATS.</p> <p>Note</p> <p>Please make sure that you have Singularity and Snakemake installed on your system and cloned the SnakeNgs repository.</p>"},{"location":"usage/rMATS/#workflow","title":"Workflow","text":"<p>The rulegraph was created by snakevision.</p> <ol> <li>Parse the experiment table to create the sample list.</li> <li>Run rMATS with <code>--novelSS</code> and the parameters specified in the <code>config.yaml</code> file.</li> </ol>"},{"location":"usage/rMATS/#usage","title":"Usage","text":"<pre><code>snakemake -s /path/to/SnakeNgs/snakefile/rMATS.smk \\\n--configfile /path/to/config.yaml \\\n--cores &lt;int&gt; \\\n--use-singularity \\\n--rerun-incomplete\n</code></pre> <p><code>config.yaml</code> should contain the following information:</p> <pre><code>workdir: /path/to/output\nexperiment_table: /path/to/experiment_table.tsv\ngtf: /path/to/reference_transcriptome.gtf # Use unzipped GTF file\n\n# rMATS\nlayout: paired # single or paired\nreadLength: 101 # Read length of the RNA-seq data\ncstat: 0.1 # Cutoff for the statistical test\nanchorLength: 6 # Anchor length for the reads\nmil: 0 # Minimum intron length\nmel: 10000 # Maximum exon length\n</code></pre> <ul> <li><code>/path/to/output</code> is the directory where the output files will be saved.</li> <li><code>/path/to/experiment_table.tsv</code> is a tab-separated file, which is same as the one used in Shiba.</li> </ul> <pre><code>sample  bam group\nsample1 /path/to/sample1.bam    Ref\nsample2 /path/to/sample2.bam    Ref\nsample3 /path/to/sample3.bam    Ref\nsample4 /path/to/sample4.bam    Alt\nsample5 /path/to/sample5.bam    Alt\nsample6 /path/to/sample6.bam    Alt\n</code></pre> <p>The <code>group</code> column must be specified as <code>Ref</code> or <code>Alt</code>. This workflow will perform the differential splicing analysis between the two groups.</p> <ul> <li><code>/path/to/reference_transcriptome.gtf</code> is the reference transcriptome in GTF format (e.g. <code>Homo_sapiens.GRCh38.106.gtf</code> for human transcriptome). Note that the GTF file should be unzipped.</li> </ul>"},{"location":"usage/rMATS/#docker-image-used-in-the-workflow","title":"Docker image used in the workflow","text":"<ul> <li>xinglab/rmats:v4.3.0</li> </ul>"}]}